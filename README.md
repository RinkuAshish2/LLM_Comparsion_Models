# LLM_Comparsion_Models
LLM Comparison Model that evaluates and compares responses from Gemini, OpenAI, and Hugging Face models using the same prompts to analyze accuracy, reasoning quality, and performance, helping users understand strengths and limitations of each LLM.

ğŸš€ LLM Nexus â€“ Enterprise LLM Comparison Platform

LLM Nexus is a Streamlit-based web application that enables side-by-side comparison of multiple Large Language Models (LLMs) such as OpenAI (ChatGPT), Google Gemini, and Meta LLaMA.
The platform supports parallel execution, fallback handling, authentication, and report generation, making it suitable for academic, research, and enterprise evaluation.

ğŸ“Œ Project Objective

The main goal of this project is to:

Analyze and compare responses from different LLMs

Understand performance, accuracy, and reliability of LLMs

Provide a unified interface to evaluate multiple AI models

Handle API failures using fallback mechanisms


ğŸ§± Project Structure
LLM_Model_Project/
â”‚
â”œâ”€â”€ app.py # Main Streamlit application
â”œâ”€â”€ auth.py # Authentication & access control
â”œâ”€â”€ config.py # Application configuration
â”‚
â”œâ”€â”€ models/ # LLM integrations
â”‚ â”œâ”€â”€ chatgpt_model.py # OpenAI ChatGPT integration
â”‚ â”œâ”€â”€ gemini_model.py # Google Gemini integration
â”‚ â””â”€â”€ llama_model.py # Meta LLaMA integration
â”‚
â”œâ”€â”€ utils/ # Utility modules
â”‚ â”œâ”€â”€ router.py # Model routing & fallback logic
â”‚ â”œâ”€â”€ parallel.py # Parallel execution handler
â”‚ â”œâ”€â”€ rate_limiter.py # API rate limiting
â”‚ â””â”€â”€ report.py # Response comparison & reports
â”‚
â”œâ”€â”€ data/ # Input / output storage
â”œâ”€â”€ .env # API keys (ignored in GitHub)
â”œâ”€â”€ .venv/ # Virtual environment (ignored)
â””â”€â”€ pycache/ # Cache files


ğŸ› ï¸ Technologies Used

Python 3.10

Streamlit â€“ Web UI

Pandas â€“ Data processing

dotenv â€“ Environment variable management

Parallel Processing

REST APIs â€“ OpenAI, Gemini, LLaMA

ğŸ¤– Supported LLMs
Model	Provider
ChatGPT	OpenAI
Gemini	Google
LLaMA	Meta


âš™ï¸ Key Features

ğŸ” User authentication

âš¡ Parallel execution of LLMs

ğŸ” Fallback handling

â³ API rate limiting

ğŸ“Š Response comparison reports

ğŸŒ Interactive Streamlit dashboard


â–¶ï¸ How to Run the Project
1ï¸âƒ£ Clone Repository
git clone https://github.com/your-username/LLM_Model_Project.git
cd LLM_Model_Project
2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
.venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Configure API Keys

Create a .env file:

OPENAI_API_KEY=your_api_key
GEMINI_API_KEY=your_api_key
HUGGINGFACE_API_KEY=your_api_key

5ï¸âƒ£ Run Application
streamlit run app.py

ğŸ“ˆ Applications / Use Cases

LLM benchmarking

AI model selection

Research & academic projects

Enterprise AI evaluation

NLP performance comparison
